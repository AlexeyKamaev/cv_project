import streamlit as st
import matplotlib.pyplot as plt
import numpy as np

from torchvision.transforms import ToTensor
from torchvision import transforms as T
import torch.nn.functional as F
import torch

from PIL import Image
import cv2



import datetime

from models.autoencoder import autoencoder

model = autoencoder

PATH = 'models\weights.pt'

model.load_state_dict(torch.load(PATH))


device = 'cpu'
model.to(device)

st.markdown("""
    <style>
        section[data-testid="stSidebar"][aria-expanded="true"]{
            display: none;
        }
    </style>
    """, unsafe_allow_html=True)





def get_prediction(image: str):

    preprocessing = T.Compose(
    [
        T.ToPILImage(),
        T.Resize((400, 400)),
        T.ToTensor()
    ]
)

    numpydata = np.asarray(image)

    x,y  = numpydata.shape[0], numpydata.shape[1]
    try:
        imag = cv2.cvtColor(numpydata, cv2.COLOR_BGR2GRAY)
    except:
        imag = T.ToTensor()(image)


    img = preprocessing(imag)


    model.to('cpu')
    model.eval()

    back = T.Compose(
    [
        T.ToPILImage(),
        T.Resize((x, y)),
    ]
)
    
    with torch.no_grad():
        pred = model(img.unsqueeze(0)).squeeze().detach()
        pred = back(pred)

    return pred


st.markdown("""
    <style>
        section[data-testid="stSidebar"][aria-expanded="true"]{
            display: none;
        }
    </style>
    """, unsafe_allow_html=True)

st.title('–ß–∏—Å—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤')

uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", type=["jpg", "jpeg", "png"], accept_multiple_files=True)

if uploaded_file is not None:

    for image in uploaded_file:
        now = datetime.datetime.now()

        image = Image.open(image)

        st.image(image, caption="–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", use_column_width=None)

        prediction = get_prediction(image)
        # st.success(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {prediction}")
        finish = datetime.datetime.now()
        elapsed_time = finish - now
        st.image(prediction, caption="–†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã –Ω–µ–π—Ä–æ—Å–µ—Ç–∏", use_column_width=None)
        # st.write(f' –ó–∞—Ç—Ä–∞—á–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É:  –ß : –ú : –° : –ú–° ----> {elapsed_time}.')
        st.write('\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n')
st.page_link("main.py", label="Home", icon="üè†")

st.title('–û–ø–∏—Å–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏')

st.header("–ú–æ–¥–µ–ª—å —É—á–∏–ª–∞—Å—å –Ω–∞ 20 —ç–ø–æ—Ö–∞—Ö.", divider='rainbow')
joke = st.slider("–°–∫–æ–ª—å–∫–æ –ø–æ –≤–∞—à–µ–º—É –µ—ë –Ω—É–∂–Ω–æ —É—á–∏—Ç—å?", 0, 100, (20))

if joke != 20:
    st.write('–ú—ã –Ω–µ–ø—Ä–µ–º–µ–Ω–Ω–æ —É—á—Ç—ë–º –≤–∞—à–µ –º–Ω–µ–Ω–∏–µ')
    st.caption(':blue[***–°–ø–∞—Å–∏–±–æ!!!!***]')

st.divider()  # üëà Draws a horizontal rule

st.header("–û–±—ä–µ–º train-–≤—ã–±–æ—Ä–∫–∏", divider='blue')
st.write("–û–±—ä–µ–º train-–≤—ã–±–æ—Ä–∫–∏ —Å–æ—Å—Ç–æ–≤–ª—è–ª 12:red[69] –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")

st.divider()  # üëà Another horizontal rule

st.header("RMSE –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ —Å–æ—Å—Ç–∞–≤–∏–ª 0.014", divider='orange')
# import base64
# gif = "media\RMSE.gif"

# file_ = open(gif, "rb")
# contents = file_.read()
# data_url = base64.b64encode(contents).decode("utf-8")
# file_.close()

# st.markdown(
#     f'<img src="data:image/gif;base64,{data_url}" alt="cat gif">',
#     unsafe_allow_html=True,
# )
st.divider()  # üëà Another horizontal rule


st.header('–ö–æ–¥ –º–æ–¥–µ–ª–∏', divider='rainbow')

code = '''class ConvEncoder(nn.Module):

    def __init__(self):
        super().__init__()
        self.layer1 = nn.Sequential(
            nn.Conv2d(1, 16, kernel_size=2, padding=1),
            nn.LazyBatchNorm2d(),
            nn.SELU()
        )
        self.layer2 = nn.Sequential(
            nn.Conv2d(16, 128, kernel_size=3, padding=1),
            nn.LazyBatchNorm2d(),
            nn.SELU()
        )
        self.layer3 = nn.Sequential(
            nn.Conv2d(128, 256, kernel_size=4, padding=2),
            nn.LazyBatchNorm2d(),
            nn.ReLU()
        )
        self.layer4 = nn.Sequential(
            nn.Conv2d(256, 64, kernel_size=4, padding=2),
            nn.LazyBatchNorm2d(),
            nn.Sigmoid()
        )

        self.layer1_t = nn.Sequential(
            nn.ConvTranspose2d(64, 256, kernel_size=4, padding=2),
            nn.LazyBatchNorm2d(),
            nn.SELU()
        )
        self.layer2_t = nn.Sequential(
            nn.ConvTranspose2d(256, 128, kernel_size=4, padding=2),
            nn.LazyBatchNorm2d(),
            nn.ReLU()
        )
        self.layer3_t = nn.Sequential(
            nn.ConvTranspose2d(128, 16, kernel_size=3, padding=1),
            nn.LazyBatchNorm2d(),
            nn.Sigmoid()
        )
        self.layer4_t = nn.Sequential(
            nn.ConvTranspose2d(16, 1, kernel_size=2, padding=1),
            nn.LazyBatchNorm2d(),
            nn.Sigmoid()
        )

    def encode(self, x):
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)
        return x


    def decode(self, x):
        x = self.layer1_t(x)
        x = self.layer2_t(x)
        x = self.layer3_t(x)
        x = self.layer4_t(x)
        return x

    def forward(self, x):
        latent = self.encode(x)
        out = self.decode(latent)
        return out'''


st.code(code, language='python')

